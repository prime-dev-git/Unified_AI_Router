# ===== CLOUD PROVIDERS (Required for cloud APIs) =====
OPENAI_API_KEY=XXXXXXXX
ANTHROPIC_API_KEY=XXXXXXX
GEMINI_API_KEY=XXXXXXX

# ===== OLLAMA (Local LLMs - Optional but recommended) =====
# Leave blank to auto-detect default Ollama server at http://localhost:11434
OLLAMA_HOST=http://localhost:11434
# Default model to use when none specified (must be pulled first!)
DEFAULT_OLLAMA_MODEL=llama3.2:3b

# ===== DEFAULT MODELS =====
DEFAULT_OPENAI_MODEL=gpt-4o-mini
DEFAULT_ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
DEFAULT_GEMINI_MODEL=gemini-1.5-flash

# ===== SECURITY =====
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000